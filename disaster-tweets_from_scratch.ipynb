{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-10T11:06:03.431375Z",
     "iopub.status.busy": "2024-12-10T11:06:03.431081Z",
     "iopub.status.idle": "2024-12-10T11:06:03.789713Z",
     "shell.execute_reply": "2024-12-10T11:06:03.789004Z",
     "shell.execute_reply.started": "2024-12-10T11:06:03.431347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T11:06:03.791314Z",
     "iopub.status.busy": "2024-12-10T11:06:03.790916Z",
     "iopub.status.idle": "2024-12-10T11:06:03.888329Z",
     "shell.execute_reply": "2024-12-10T11:06:03.887369Z",
     "shell.execute_reply.started": "2024-12-10T11:06:03.791277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train= pd.read_csv('train.csv')\n",
    "test= pd.read_csv('test.csv')\n",
    "#ss= pd.read_csv('sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T11:06:03.889986Z",
     "iopub.status.busy": "2024-12-10T11:06:03.889669Z",
     "iopub.status.idle": "2024-12-10T11:06:03.906343Z",
     "shell.execute_reply": "2024-12-10T11:06:03.905571Z",
     "shell.execute_reply.started": "2024-12-10T11:06:03.889949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T11:06:03.908858Z",
     "iopub.status.busy": "2024-12-10T11:06:03.908592Z",
     "iopub.status.idle": "2024-12-10T11:06:03.922851Z",
     "shell.execute_reply": "2024-12-10T11:06:03.921781Z",
     "shell.execute_reply.started": "2024-12-10T11:06:03.908834Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1\n",
       "2   5  All residents asked to 'shelter in place' are ...       1\n",
       "3   6  13,000 people receive #wildfires evacuation or...       1\n",
       "4   7  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train[['id','text','target']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T11:06:03.924414Z",
     "iopub.status.busy": "2024-12-10T11:06:03.924103Z",
     "iopub.status.idle": "2024-12-10T11:06:09.139857Z",
     "shell.execute_reply": "2024-12-10T11:06:09.138915Z",
     "shell.execute_reply.started": "2024-12-10T11:06:03.924380Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/abid.abderrazek/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  our deeds are the reason of this earthquake ma...       1\n",
       "1   4              forest fire near la ronge sask canada       1\n",
       "2   5  all residents asked to shelter in place are be...       1\n",
       "3   6  13000 people receive wildfires evacuation orde...       1\n",
       "4   7  just got sent this photo from ruby alaska as s...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "nltk.download('stopwords')\n",
    "def clean_text(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "  text = re.sub(r'\\s+', ' ', text)\n",
    "  return text\n",
    "def remove_stopwards(text):\n",
    "  stopword = set(stopwords.words('english'))\n",
    "  words = text.split()\n",
    "  filtered_words = [word for word in words if word.lower() not in stopword]\n",
    "  return ' '.join(filtered_words)\n",
    "train['text'] = train['text'].apply(clean_text)\n",
    "\n",
    "test['text'] = test['text'].apply(clean_text)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T11:06:25.010335Z",
     "iopub.status.busy": "2024-12-10T11:06:25.009833Z",
     "iopub.status.idle": "2024-12-10T11:06:25.014277Z",
     "shell.execute_reply": "2024-12-10T11:06:25.013468Z",
     "shell.execute_reply.started": "2024-12-10T11:06:25.010307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "USE_ALL_TO_TRAIN=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abid.abderrazek/.conda/envs/compet/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device='cuda'\n",
    "else:\n",
    "    device='cpu'\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "model_checkpoint='garynguyen1174/disaster_tweet_bert'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T11:06:25.015585Z",
     "iopub.status.busy": "2024-12-10T11:06:25.015288Z",
     "iopub.status.idle": "2024-12-10T11:06:30.684800Z",
     "shell.execute_reply": "2024-12-10T11:06:30.683904Z",
     "shell.execute_reply.started": "2024-12-10T11:06:25.015559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, ClassLabel\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset['text'],padding='max_length',max_length=90)\n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train': 'train.csv'})\n",
    "dataset = dataset.rename_column('target', 'label')\n",
    "dataset = dataset.cast_column('label', ClassLabel(num_classes=2, names=['negative', 'positive']))\n",
    "dataset = dataset.map(tokenize_dataset, batched=True)\n",
    "if not USE_ALL_TO_TRAIN:\n",
    "    dataset = dataset['train'].train_test_split(test_size=0.2, stratify_by_column='label', seed=1)\n",
    "\n",
    "dataset_test = load_dataset('csv', data_files={'test': 'test.csv'})\n",
    "dataset_test = dataset_test.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenized_train_dataset = dataset['train'].remove_columns(['id', 'keyword', 'location', 'text'])\n",
    "\n",
    "if not USE_ALL_TO_TRAIN:\n",
    "    tokenized_test_dataset = dataset['test'].remove_columns(['id', 'keyword', 'location', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T11:17:06.853016Z",
     "iopub.status.busy": "2024-12-10T11:17:06.852132Z",
     "iopub.status.idle": "2024-12-10T11:17:06.888134Z",
     "shell.execute_reply": "2024-12-10T11:17:06.887429Z",
     "shell.execute_reply.started": "2024-12-10T11:17:06.852980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from transformers import DataCollatorWithPadding \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "# Import wandb\n",
    "import wandb\n",
    "\n",
    "config={\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\":16,\n",
    "    \"Eval_batch_size\":64\n",
    "    }\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Disaster Tweets 2\",\n",
    "    name=f\"{model_checkpoint}{config['epochs']}-{config['learning_rate']}-batch{config['batch_size']}\",     # Custom name for this run\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Data Collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer,padding=True)\n",
    "\n",
    "def compute_loss(logis,targets):\n",
    "    loss_fn = CrossEntropyLoss(reduction='sum')\n",
    "    loss=loss_fn(logis,targets)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Compute Metrics\n",
    "def compute_metrics(logits, labels):\n",
    "    logits = logits.cpu().detach().numpy()\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return {'f1_score': f1_score(labels, predictions)}\n",
    "\n",
    "def compute_f1(predictions, labels):\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    return {'f1_score': f1_score(labels, predictions)}\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader=DataLoader(tokenized_train_dataset,batch_size=config['batch_size'],collate_fn=data_collator)\n",
    "if not USE_ALL_TO_TRAIN:\n",
    "    test_dataloader=DataLoader(tokenized_test_dataset,batch_size=config['Eval_batch_size'],collate_fn=data_collator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TesT Model from training using Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('rob_good.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abid.abderrazek/.conda/envs/compet/lib/python3.13/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "optimizer=AdamW(model.parameters(),config['learning_rate'],weight_decay=0.01)\n",
    "\n",
    "steps=0\n",
    "total_steps=config['epochs']*len(train_dataloader)\n",
    "for _ in range(1,config['epochs']):\n",
    "    for idx,val in enumerate(train_dataloader):\n",
    "        if not USE_ALL_TO_TRAIN:\n",
    "            if steps==0:\n",
    "                all_preds=[]\n",
    "                all_labels=[]\n",
    "                for t_idx,t_val in enumerate(test_dataloader):\n",
    "                    val0=t_val\n",
    "                    out= model(input_ids=val0['input_ids'].to(device),attention_mask=val0['attention_mask'].to(device))\n",
    "                    targets=val0['labels']\n",
    "                    preds=torch.argmax(out.logits,dim=1)\n",
    "                    all_preds.append(preds)\n",
    "                    all_labels.append(targets)\n",
    "                all_preds = torch.cat(all_preds)\n",
    "                all_labels = torch.cat(all_labels)\n",
    "                f1=compute_f1(all_preds,all_labels)\n",
    "                print(f'eval {steps}    ', f1)\n",
    "                wandb.log({\"f1\": f1})\n",
    "\n",
    "        out= model(input_ids=val['input_ids'].to(device),attention_mask=val['attention_mask'].to(device))\n",
    "        targets=val['labels']\n",
    "        loss=compute_loss(out.logits.to(device),targets.to(device))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if not USE_ALL_TO_TRAIN:\n",
    "            if steps%10==0:\n",
    "                all_preds=[]\n",
    "                all_labels=[]\n",
    "                for t_idx,t_val in enumerate(test_dataloader):\n",
    "                    val0=t_val\n",
    "                    out= model(input_ids=val0['input_ids'].to(device),attention_mask=val0['attention_mask'].to(device))\n",
    "                    targets=val0['labels']\n",
    "                    preds=torch.argmax(out.logits,dim=1)\n",
    "                    all_preds.append(preds)\n",
    "                    all_labels.append(targets)\n",
    "                all_preds = torch.cat(all_preds)\n",
    "                all_labels = torch.cat(all_labels)\n",
    "                f1=compute_f1(all_preds,all_labels)\n",
    "                print(f'eval {steps} / {total_steps}  ', f1)\n",
    "                wandb.log({\"f1\": f1})\n",
    "\n",
    "        wandb.log({\"loss\": loss})\n",
    "        steps+=1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▂▄▃▁▂▅▄▂▃▆▃▃▅▂▃▁▃▄█▁▄▃▄▃▅▄▄▂▅▁▅▁▇▂▃▄▁▁▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.25977</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">garynguyen1174/disaster_tweet_bert2-1e-05-batch16</strong> at: <a href='https://wandb.ai/abderrazek-abid/Disaster%20Tweets%202/runs/ic2rvizx' target=\"_blank\">https://wandb.ai/abderrazek-abid/Disaster%20Tweets%202/runs/ic2rvizx</a><br/> View project at: <a href='https://wandb.ai/abderrazek-abid/Disaster%20Tweets%202' target=\"_blank\">https://wandb.ai/abderrazek-abid/Disaster%20Tweets%202</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241211_170640-ic2rvizx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "torch.save(model,'best.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-abid.abderrazek-84557/ipykernel_1505554/1128040631.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model=torch.load('best.pth')\n",
      "/home/abid.abderrazek/.conda/envs/compet/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model=torch.load('best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m all_preds\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      2\u001b[0m all_labels\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t_idx,t_val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtest_dataloader\u001b[49m):\n\u001b[1;32m      4\u001b[0m     val0\u001b[38;5;241m=\u001b[39mt_val\n\u001b[1;32m      5\u001b[0m     out\u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39mval0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),attention_mask\u001b[38;5;241m=\u001b[39mval0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "all_preds=[]\n",
    "all_labels=[]\n",
    "for t_idx,t_val in enumerate(test_dataloader):\n",
    "    val0=t_val\n",
    "    out= model(input_ids=val0['input_ids'].to(device),attention_mask=val0['attention_mask'].to(device))\n",
    "    targets=val0['labels']\n",
    "    preds=torch.argmax(out.logits,dim=1)\n",
    "    all_preds.append(preds)\n",
    "    all_labels.append(targets)\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_score': 0.8885496183206106}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(all_preds,all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sub_dataset = dataset_test.remove_columns(['id', 'keyword', 'location', 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0'), torch.Size([3263]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sub_dataloader=DataLoader(tokenized_sub_dataset['test'],batch_size=config['Eval_batch_size'],collate_fn=data_collator)\n",
    "all_subs=[]\n",
    "for t_idx,t_val in enumerate(sub_dataloader):\n",
    "                val0=t_val\n",
    "                out= model(input_ids=val0['input_ids'].to(device),attention_mask=val0['attention_mask'].to(device))\n",
    "                preds=torch.argmax(out.logits,dim=1)\n",
    "                all_subs.append(preds)\n",
    "all_subs = torch.cat(all_subs)\n",
    "all_subs,all_subs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-10T11:06:30.695715Z",
     "iopub.status.idle": "2024-12-10T11:06:30.696033Z",
     "shell.execute_reply": "2024-12-10T11:06:30.695882Z",
     "shell.execute_reply.started": "2024-12-10T11:06:30.695867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': dataset_test['test']['id'],\n",
    "    'target': list(all_subs.cpu().detach().numpy())\n",
    "})\n",
    "submission_df.to_csv('submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "compet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
